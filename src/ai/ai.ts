import { createGoogleGenerativeAI } from "@ai-sdk/google";
import { createGroq } from "@ai-sdk/groq";
import {
  type CoreMessage,
  type CoreTool,
  generateObject,
  streamText,
} from "ai";
import React from "react";
import { createRoot } from "react-dom/client";
import { z } from "zod";
import { StreamMessage } from "~/components/StreamMessage";
import {
  DEFAULT_MODEL,
  DEFAULT_MODEL_PROVIDER,
  MODEL_PROVIDERS,
  type ModelProvider,
} from "~/utils/constants";
import { loadApiKey, turndown } from "~ai/utils";
import { MemVector } from "~ai/vector";
import type { KnowledgeCardData } from "~components/KnowledgeCard";
import type { MindmapData } from "~components/Mindmap";
import { type Tools, toolRegistry } from "./tools";

const siEnglishTeacher =
  "ä½ æ˜¯ä¸€åèµ„æ·±è‹±è¯­è€å¸ˆæœ‰ä¸°å¯Œçš„æ•™å­¦ç»éªŒï¼Œå¯ä»¥æ·±å…¥æµ…å‡ºçš„ç”¨ä¸­æ–‡è®²è§£è‹±æ–‡ç–‘éš¾æ‚å¥å’Œå•è¯é‡Šä¹‰ã€‚";
const siSummariser =
  "You are good at summarising articles. Your summary is interesting and informative.  ";

const siCodeExpert = `
  You are a coding expert. You are good at:
  1. Explaining code snippets.
  2. Rewriting an existing code snippet into a new code snippet with a specified programming language.
  3. Explaining the reason of the given error messages.`;

const ocrExpert = (postProcessing: string) => {
  const ocrPrompt = `
  OCR this image. Extract the text as it is, without analyzing or summarizing. If there is post-processing, apply it after OCR.

  Before OCR, consider the following pre-processing steps:
  1. **Noise reduction:** Apply Gaussian blur with a sigma of 1.5 to reduce noise.
  2. **Binarization:** Use adaptive thresholding with a block size of 11 and C=2 to convert the image to black and white.
  3. **Deskewing:** Correct the image tilt using OpenCV's 'findContours' and 'minAreaRect' functions.
  4. **Sharpening:** Apply unsharp masking with a kernel size of 3, sigma of 1, and amount of 0.5 to enhance edges.

  If the text is handwritten or the image has a complex background, consider additional steps like morphological operations or perspective correction.
`;
  if (postProcessing) {
    const postPrompt = `
      After OCR, do the following post-processing steps and return the final result, with the text extracted from the image.
      ${postProcessing}
    `;
    return `${ocrPrompt}\n\n${postPrompt}`;
  }
  return ocrPrompt;
};

const pageRagPrompt = (context: string) => {
  return `
  You are a helpful assistant and can do the following tasks:
  1. answering users's question based on the given context.
  2. finding relevant information based on the input.

  Workflow:
  1. try to answer the question based on the context.
  2. if the context is not sufficient, ask the user if he/she wants to search on web.
  3. if the user agrees, search the web and provide the answer. Don't try to answer the question without searching.

  Try to keep the answer concise and relevant to the context without providing unnecessary information and explanations.
  If you don't know how answer, just respond "I could not find the answer based on the context you provided."

  Page Context:
  ${context}
  `;
};

const siMindmap = `Based on the given article:
        1. try to summary and extra the key points for the diagram generation.
        2. these key points must be informative and concise.
        3. these key points should highlight the author's viewpoints.
        4. try to keep the key points in a logical order.
        5. don't include any extra explanation and irrelevant information.

        Use them to generate a Mindmap.
        Mindmap syntax rules:
        - Each line should not have any quotes marks
        - Do not include 'mermaid' at the start of the diagram
        - Do not use 3-nesting parentheses for root, ie: "root((Mixture of Experts (MoE)))". The correct is "root((MoE))"
        - Do not use abbreviations with parentheses in the middle of a line, but it can be used at the end of a line
        - Do not use any special characters in the diagram except emojis
        - Keep function name without parameters when you are reading a programming article, ie: free, not free()
        - Can only have one root node, ie no other node can be at the same level as the root node.
        - Basic structure example:
        <Basic Structure>
        mindmap
          Root
            A
              B
              C

        Each node in the mindmap can be different shapes:
        <Square>
        id[I am a square]
        <Rounded square>
        id(I am a rounded square)
        <Circle>
        id((I am a circle))
        <Bang>
        id))I am a bang((
        <Cloud>
        id)I am a cloud(
        <Hexagon>
        id{{I am a hexagon}}
        <Default>
        I am the default shape

        Icons can be used in the mindmap with syntax: "::icon()"

        Markdown string can be used like the following:
        <Markdown string>
        mindmap
            id1["\`**Root** with
        a second line
        Unicode works too: ğŸ¤“\`"]
              id2["\`The dog in **the** hog... a *very long text* that wraps to a new line\`"]
              id3[Regular labels still works]

        Here is a mindmap example:
        <example mindmap>
        mindmap
          root((mindmap))
            Origins
              Long history
              ::icon(fa fa-book)
              Popularisation
                British popular psychology author Tony Buzan
            Research
              On effectiveness<br/>and features
              On Automatic creation
                Uses
                    Creative techniques
                    Strategic planning
                    Argument mapping
            Tools
              Pen and paper
              Mermaid

        The max deepth of the generated mindmap should be 4.

        The output syntax should be correct. Try to avoid the following common errors:
        - never use \" in the output
        - \`\`\`mermaid in the output
        <error examples>
        - Gating network (G) decides experts (E)
          - fixed: Gating network decides experts
        - root((Mixture of Experts (MoE)))
          - fixed: root((MoE))
        - 2017: Shazeer et al. (Google) - 137B LSTM
          - fixed: 2017: Shazeer et al. Google 137B LSTM
        - calloc()
          - fixed: calloc
        - sbrk(0) returns current break
          - fixed: sbrk:0 returns current break
        - Allocate N + sizeof(header_t) bytes
          - fixed: Allocate N + sizeof header_t bytes

        Review the output to ensure it is logical and follows the correct syntax, if not, correct it.
    `;

const siKnowledge =
  "åˆ†ææ–‡æœ¬å¹¶è¾“å‡ºæ–‡ç« æ‘˜è¦ï¼Œå…³é”®å­—ï¼Œæ¦‚è¿°ï¼Œåˆ†èŠ‚é˜…è¯»ï¼Œç›¸å…³å·¥å…·å’Œå‚è€ƒæ–‡çŒ®ã€‚éœ€è¦æ³¨æ„ï¼š5ä¸ªå…³é”®å­—ï¼Œ5ä¸ªå…³é”®ç‚¹";

const prepareSystemPrompt = (
  pageText: string,
  pageURL: string,
  customPrompt?: string,
) => {
  if (customPrompt) {
    return `${customPrompt}\nPage Context:\n${pageText}\nPage URL: ${pageURL}`;
  }

  return `${pageRagPrompt(pageText)}\nPage URL: ${pageURL}`;
};

export const callPrompt = async (
  prompt: string,
  system: string,
  messageElement: HTMLElement,
) => {
  const root = createRoot(messageElement);

  try {
    const apiKey = await loadApiKey("gemini");
    const google = createGoogleGenerativeAI({ apiKey });
    const { textStream } = streamText({
      model: google("gemini-2.0-flash-exp"),
      system,
      prompt,
    });

    const results: string[] = [];
    for await (const text of textStream) {
      results.push(text);
      root.render(
        React.createElement(StreamMessage, { outputString: results.join("") }),
      );
    }
    return results;
  } catch (e) {
    root.render(
      React.createElement(StreamMessage, { outputString: e.message }),
    );
  }
};

const genChatFunction = async (
  messages: Array<CoreMessage>,
  messageElement: HTMLElement,
) => {
  const root = createRoot(messageElement);

  try {
    const apiKey = await loadApiKey("gemini");
    const google = createGoogleGenerativeAI({ apiKey });
    const { textStream } = streamText({
      model: google("gemini-2.0-flash-exp"),
      messages,
    });

    const results: string[] = [];
    for await (const text of textStream) {
      results.push(text);
      root.render(
        React.createElement(StreamMessage, { outputString: results.join("") }),
      );
    }
  } catch (e) {
    root.render(
      React.createElement(StreamMessage, { outputString: e.message }),
    );
  }
};

export const explainSentence = (
  sentences: string,
  messageElement: HTMLElement,
) =>
  callPrompt(
    `è§£é‡Šè¯¥è‹±æ–‡çš„è¯­æ³•ç»“æ„ï¼š"${sentences}"ï¼Œæ‹†è§£å¥å‹ã€å…³é”®çŸ­è¯­å’Œä¹ æƒ¯ç”¨è¯­ï¼Œæ·±å…¥æµ…å‡ºä»¥ä¾¿å­¦ç”Ÿå¯ä»¥ç†è§£ã€‚æœ€åç¿»è¯‘å…¨å¥ã€‚`,
    siEnglishTeacher,
    messageElement,
  );

export const explainWord = (word: string, messageElement: HTMLElement) =>
  callPrompt(
    `è§£é‡Šè¯¥è‹±è¯­å•è¯ï¼š"${word}"ï¼Œç¿»è¯‘å¹¶ä»‹ç»å…¶å‘éŸ³ã€è¯æºã€è¯æ ¹ã€å…¸å‹ä¾‹å¥ï¼Œä»¥åŠåŒä¹‰è¯å’Œåä¹‰è¯ã€‚`,
    siEnglishTeacher,
    messageElement,
  );

export const summariseLink = async (
  root: HTMLElement,
  link: string,
  messageElement: HTMLElement,
) => {
  return await callPrompt(
    `åˆ†ææ–‡æœ¬å¹¶è¾“å‡ºæ–‡ç« æ‘˜è¦ï¼Œå…³é”®å­—ï¼Œæ¦‚è¿°ï¼Œåˆ†èŠ‚é˜…è¯»ï¼Œç›¸å…³å·¥å…·å’Œå‚è€ƒæ–‡çŒ®ã€‚
    ${turndown(root, "code")}
    è¾“å‡ºæ ¼å¼è¦æ±‚å¦‚ä¸‹ï¼š
    è¯­è¨€ï¼š é‡‡ç”¨åŸæ–‡åŒè¯­ç§ã€‚å¦‚ï¼šåŸæ–‡æ˜¯è‹±æ–‡ï¼Œè¾“å‡ºç”¨è‹±æ–‡ï¼›åŸæ–‡æ˜¯ä¸­æ–‡ï¼Œè¾“å‡ºç”¨ä¸­æ–‡ï¼Œä»¥æ­¤ç±»æ¨ã€‚
    å…³é”®å­—ï¼š 5 ä¸ªä»¥å†…ã€‚ç”¨è‹±æ–‡é€—å·åˆ†éš”ã€‚ä¾‹å¦‚ï¼š key1, key2, ...
    æ¦‚è¿°ï¼š200 å­—ä»¥å†…ï¼Œéœ€è¦çªå‡ºä½œè€…æƒ³è¦å¼ºè°ƒçš„è¦æ—¨
    åˆ†èŠ‚é˜…è¯»ï¼š
      - å¦‚æœæœ‰ <h2>ï¼Œé‚£ä¹ˆå°†æ¯ä¸ª <h2> æ€»ç»“æˆ 3 å¥è¯ï¼Œé¿å…è”æƒ³ï¼Œå¹¶æŒ‰åŸæ–‡ä¸€æ ·çš„é¡ºåºæ’åˆ—è¾“å‡ºã€‚
      - å¦åˆ™ï¼Œé‚£ä¹ˆæŒ‰æ®µè½å¤§æ„çš„ç›¸ä¼¼æ€§è¿›è¡Œå½’ç±»ï¼Œæ€»ç»“è¾“å‡ºã€‚
    ç›¸å…³å·¥å…·ï¼šå¦‚æœæ–‡ç« ä¸­æåˆ°äº†ä¸€äº›å·¥å…·ï¼Œåœ¨æ­¤å¤„åˆ—å‡ºç›¸å…³å·¥å…·çš„åç§°å’Œé“¾æ¥ã€‚
    å‚è€ƒæ–‡çŒ®ï¼šå¦‚æœæœ‰å‚è€ƒæ–‡çŒ®ï¼Œåˆ—å‡ºå‚è€ƒæ–‡çŒ®çš„åç§°å’Œé“¾æ¥ã€‚
    åŸæ–‡é“¾æ¥ï¼š${link}ã€‚
    æœ€åè¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼Œç¡®ä¿æ•´ä¸ªè¾“å‡ºä¸ä¼šå‡ºç°å‰åçŸ›ç›¾ä¸åŸæ–‡ä¸ç¬¦çš„åœ°æ–¹ï¼ŒåŒæ—¶ä¿è¯æ®µè½é¡ºåºçš„ä¸€è‡´æ€§ã€‚`,
    siSummariser,
    messageElement,
  );
};

export const explainCode = (message: string, messageElement: HTMLElement) =>
  callPrompt(
    `åˆ†æï¼š ${message} ï¼Œå¹¶ç»™å‡ºæ¸…æ™°çš„è§£é‡Šã€‚
    1. è¯†åˆ«ç±»å‹ï¼šä»£ç ã€é”™è¯¯ä¿¡æ¯æˆ–å‘½ä»¤è¡Œè¾“å‡ºã€‚
    2. å¦‚æœæ˜¯ä»£ç ï¼Œåˆ™ç»™å‡ºå¯èƒ½çš„å¼€å‘è¯­è¨€ï¼Œè§£é‡Šä»£ç çš„é€»è¾‘å’ŒåŠŸèƒ½ï¼Œå¿½ç•¥ä»£ç ä¸­çš„æ³¨é‡Šã€å¯¼å…¥ã€ç±»å‹å®šä¹‰ã€æ‰“å°è¾“å‡ºã€‚
    3. å¦‚æœæ˜¯é”™è¯¯ä¿¡æ¯ï¼Œåˆ™è§£é‡Šé”™è¯¯çš„åŸå› å’Œè§£å†³æ–¹æ³•ã€‚
    4. å¦‚æœæ˜¯å‘½ä»¤è¡Œè¾“å‡ºï¼Œåˆ™è§£é‡Šå‘½ä»¤çš„åŠŸèƒ½å’Œè¾“å‡ºçš„å«ä¹‰ã€‚
    `,
    siCodeExpert,
    messageElement,
  );

export const rewriteCode = (
  code: string,
  targetLang: string,
  messageElement: HTMLElement,
) =>
  callPrompt(
    `å°† ${code} ä»£ç é‡å†™ä¸º ${targetLang} è¯­è¨€çš„ä»£ç ã€‚`,
    siCodeExpert,
    messageElement,
  );

// TODO: Use some external image APIs for image preprocessing
// (noise reduction, binarization, deskewing, sharpening, and so on)
export const ocr = (
  url: string,
  messageElement: HTMLElement,
  postPrompt = "",
) =>
  genChatFunction(
    [
      {
        role: "user",
        content: [
          { type: "text", text: ocrExpert(postPrompt) },
          {
            type: "image",
            image: new URL(url),
          },
        ],
      },
    ],
    messageElement,
  );

export const genObject = async (
  prompt: string,
  system: string,
  schema: z.Schema,
) => {
  try {
    const apiKey = await loadApiKey("gemini");
    const google = createGoogleGenerativeAI({ apiKey });

    const { object } = await generateObject({
      model: google("gemini-2.0-flash-exp"),
      schema,
      system,
      prompt,
    });

    return object;
  } catch (e) {
    return { error: true, message: e.message };
  }
};

const MindmapSchema = z.object({
  title: z.string(),
  description: z.string(),
  diagram: z.string(),
});

export const generateMindmap = async (
  root: HTMLElement,
): Promise<MindmapData> => {
  const result = await genObject(
    turndown(root, "code"),
    siMindmap,
    MindmapSchema,
  );
  return result;
};

const KnowledgeCardSchema = z.object({
  title: z.string(),
  keywords: z.array(z.string()),
  keyPoints: z.array(z.string()),
  originalLink: z.string(),
  references: z.object({
    tools: z.array(
      z.object({
        title: z.string(),
        link: z.string(),
      }),
    ),
    attachments: z.array(
      z.object({
        title: z.string(),
        link: z.string(),
      }),
    ),
  }),
});

export const generateKnowledgeCard = async (
  root: HTMLElement,
): Promise<KnowledgeCardData> => {
  const result = await genObject(
    turndown(root, "code"),
    siKnowledge,
    KnowledgeCardSchema,
  );
  return result;
};

let pageVector: MemVector;

export const chatWithPage = async (
  messages: CoreMessage[],
  root: HTMLElement,
  pageURL: string,
  signal: AbortSignal,
  provider: ModelProvider = DEFAULT_MODEL_PROVIDER,
  modelName = DEFAULT_MODEL,
  tools: Tools = {},
  customPrompt?: string,
) => {
  if (MODEL_PROVIDERS.indexOf(provider) === -1) {
    throw new Error("Invalid provider");
  }

  let context = turndown(root);
  if (provider !== "gemini") {
    if (!pageVector) {
      pageVector = new MemVector(root);
      await pageVector.indexing();
    }

    const userMessage = messages[messages.length - 1].content.toString();
    context = (await pageVector.search(userMessage)).join("\n");
  }

  const filteredMessages = messages.filter((msg) => msg.role !== "tool");

  try {
    const apiKey = await loadApiKey(provider);
    const model =
      provider === "gemini"
        ? createGoogleGenerativeAI({ apiKey })(modelName)
        : createGroq({ apiKey })(modelName);

    const filteredTools: Record<string, CoreTool> = {};
    if (modelName !== "gemini-2.0-flash-thinking-exp") {
      for (const [key, tool] of Object.entries(tools)) {
        filteredTools[key] = tool.createCoreTool(
          toolRegistry.getToolSettings(tool.name),
        );
      }
    }

    const { textStream, toolResults } = streamText({
      model,
      system: prepareSystemPrompt(context, pageURL, customPrompt),
      tools: filteredTools,
      messages: filteredMessages,
      abortSignal: signal,
    });
    return { textStream, toolResults };
  } catch (e) {
    return e.message;
  }
};
